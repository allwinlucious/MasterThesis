{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fac08d-d1de-4ecd-b4f3-d0fc199d2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ML2.utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366a3b2-eddd-48bf-a4bd-52df4797e9f9",
   "metadata": {},
   "source": [
    "# 7. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af62c9-0dda-4520-8d2e-cd422a718922",
   "metadata": {},
   "source": [
    "## 7.1 Payload/Tool parameter identification\n",
    "\n",
    "In robotics, the identification of mass, is crucial for ensuring accurate and safe operation,\n",
    "particularly in tasks that involve dynamic interactions with the environment like pick\n",
    "and place. Traditional methods of measuring the weight of the load often require direct\n",
    "physical measurements, which can be both time-consuming and impractical in automated\n",
    "systems where multiple types of payloads are involved. This application of a the devel-\n",
    "oped model offers a significant advantage by enabling the indirect estimation of these\n",
    "parameters through the analysis of predicted forces. This increases the adaptability of\n",
    "the robot to various tools and payloads without the need for frequent recalibration or\n",
    "manual measurements or a costly FTS.\n",
    "\n",
    "Another particularly valuable use case for this technology is in detecting situations where a\n",
    "payload, after being picked up, might slip down. Such a slip can be quickly detected by the\n",
    "virtual sensor. Without this detection capability, the robot could experience unexpected\n",
    "torques and forces, leading to a sudden jerk, which could compromise the precision of\n",
    "the task or trigger false collision, resulting in lost time and money. By identifying these\n",
    "changes in real-time, the system can adjust its operations to compensate, ensuring smooth\n",
    "and safe handling of the payload."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9431454e-4f46-4e0c-ba4a-e6fd831fd90f",
   "metadata": {},
   "source": [
    "### 7.1.1 Implementation\n",
    "\n",
    "The estimation of mass using a virtual joint torque sensor is done using the estimate of forces acting on the TCP. The forces estimated by the virtual sensor, in the $X$, $Y$, and $Z$ directions, can be used to compute the overall magnitude of the force vector, which, when divided by the gravitational constant, provides an estimate of the tool's mass.\n",
    "\n",
    "In a static or quasi-static condition, the forces measured by the virtual joint torque sensor are primarily due to the weight of the tool and any attached payload. The relationship between the force components and the mass of the tool can be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "|\\vec{F}| = \\sqrt{F_x^2 + F_y^2 + F_z^2}\\tag{7.1}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "- $F_x$, $F_y$, and $F_z$ are the force components in the $X$, $Y$, and $Z$ directions, respectively.\n",
    "- $|\\vec{F}|$ is the magnitude of the resultant force vector.\n",
    "\n",
    "Given that the force due to gravity is $F = m \\cdot g$, where $g$ is the acceleration due to gravity (approximately $9.81 \\, \\text{m/s}^2$), the mass $m$ can be estimated as:\n",
    "\n",
    "\\begin{equation}m = \\frac{|\\vec{F}|}{g}\\tag{7.2}\\end{equation}\n",
    "\n",
    "To ensure accuracy, measurements are made over a period of 200 ms resulting in 100 data\n",
    "points, and the average of the calculated mass values is taken to provide a more reliable\n",
    "estimate. This approach helps to reduce the impact of sensor noise, and compensate for\n",
    "any variability in the conditions during the measurements, leading to a more accurate\n",
    "estimation of the tool’s mass. The above equation assumes that the forces measured are\n",
    "primarily due to gravity, and thus the resultant force vector provides a direct indication\n",
    "of the tool’s mass.\n",
    "\n",
    "To validate the performance of the model in this application, an eccentric mass as shown\n",
    "in <a href=\"#eccentric_tool\">Figure 7.1</a> was attached to the robot and the robot was moved along a generated\n",
    "trajectory as described in [Section 6.1](./6.0_Machine_Learning_based_approach_for_entire_robot.ipynb#6.1.-Data-Collection). A velocity scaling of 5% was applied so as to maintain a\n",
    "quasi-static condition.\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./utils/ML2/application/eccentrictool.jpeg\" id=\"eccentric_tool\" style=\"width:30%; margin: auto;\">\n",
    "    <figcaption align=\"center\"> <b>Figure 7.1.: </b> Eccentric tool mounted on LARA8 </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa6021f-9c65-4cb5-94d5-1e2eb0a32d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5efda52013d4d76811c22286bc61802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass estimated from model predictions:  2.7590842057440987 kg\n",
      "Mass estimated from FTS measurements:  2.7074553307893927 kg\n"
     ]
    }
   ],
   "source": [
    "y_max = torch.load('utils/ML2/models/y_max.pt',map_location=torch.device('cpu'))\n",
    "y_min = torch.load('utils/ML2/models/y_min.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "dataset = CustomDatasetFromCSV(csv_path = 'utils/ML2/application/lara8_0.5.csv', mode=\"test\")\n",
    "test_dataloader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "model = torch.jit.load('utils/ML2/models/model.pt', map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():    \n",
    "    for i, (X,y) in enumerate(tqdm(test_dataloader)):\n",
    "        pred = model(X)\n",
    "        #denormalize predictions\n",
    "        pred = (pred+1)/2* (y_max - y_min) + y_min\n",
    "        pred_list.append(pred)\n",
    "# Denormalize the data\n",
    "y_truth = ((test_dataloader.dataset.y + 1) / 2 * (y_max - y_min) + y_min).cpu().numpy()\n",
    "pred_list = torch.cat(pred_list).cpu().numpy()\n",
    "\n",
    "y_truth = y_truth[116:]\n",
    "\n",
    "# Example usage of your specific mass calculation\n",
    "Fx = pred_list[0:100, 0]\n",
    "Fy = pred_list[0:100, 1]\n",
    "Fz = pred_list[0:100, 2]\n",
    "\n",
    "FTx = y_truth[0:100, 0]\n",
    "FTy = y_truth[0:100, 1]\n",
    "FTz = y_truth[0:100, 2]\n",
    "\n",
    "mass_estimate = np.sqrt(Fx**2 + Fy**2 + Fz**2).mean() / 9.81\n",
    "mass_actual = np.sqrt(FTx**2 + FTy**2 + FTz**2).mean() / 9.81\n",
    "print(\"Mass estimated from model predictions: \", mass_estimate.item(),\"kg\")\n",
    "print(\"Mass estimated from FTS measurements: \", mass_actual.item(),\"kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aadac9-21d0-4e79-a3b7-11e19be30081",
   "metadata": {},
   "source": [
    "The model estimated the mass to be **2.71kg** whereas the mass estimated from FTS\n",
    "measurements was **2.76kg**. <a href=\"#table7.1\">Table 7.1</a> shows the model estimation on a number of different\n",
    "payloads. The results demonstrates that the model can be used to estimate the mass of a\n",
    "tool or object attached to the robot’s TCP reliably. This application can be extended to\n",
    "calculate the payload’s center of gravity offsets using the model’s torque predictions.\n",
    "<a id=\"table7.1\"></a> \n",
    "<table>\n",
    "    <caption style=\"caption-side:bottom; text-align:center;\"><b>Table 7.1.:</b> Comparison of Estimated and Actual Masses with Absolute Errors</caption>\n",
    "    <tr>\n",
    "        <th>Payload</th>\n",
    "        <th>Estimated Mass (kg)</th>\n",
    "        <th>Actual Mass (kg)</th>\n",
    "        <th>Absolute Error (kg)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Payload 1</td>\n",
    "        <td>2.71</td>\n",
    "        <td>2.76</td>\n",
    "        <td>0.04</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Payload 2</td>\n",
    "        <td>1.5554</td>\n",
    "        <td>1.5223</td>\n",
    "        <td>0.0331</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Payload 3</td>\n",
    "        <td>7.2118</td>\n",
    "        <td>7.1823</td>\n",
    "        <td>0.0295</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee262eb8-35c4-4947-b43e-4edd650366a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
