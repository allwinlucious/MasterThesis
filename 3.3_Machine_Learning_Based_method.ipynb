{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fae12b2-9d80-4e2f-b638-627d7f52f903",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mML1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m      3\u001b[0m graphviz\u001b[38;5;241m.\u001b[39mset_jupyter_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "File \u001b[0;32m/home/jovyan/work/utils/ML1/utils.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  Dataset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from utils.ML1.utils import *\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('png');\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42b7d9-f388-4381-bef8-583df536e8ae",
   "metadata": {},
   "source": [
    "# 3.3 Machine Learning\n",
    "As seen in chapter 3.1, both methods suffer from inaccuracies and inherent issues related to the source of torque informaiton associated with it. from chapter 3.1 it is evident that there are some nonlinearities in the residuals, these could arise from complex phenominons like hysterisis, where the residual could be related to the path travered before or the residuals could be due to inaccurasies in modeling, these cannot be compensated for by analytical methods anymore and require a more statistical approach. As proven by many recent studies which used ML for this purpose of learning the residual or for modeling complex physics phenminons. Here the approach is to make use of the torque information from both encoders as well as motor currents, other useful inputs like the joint velocity and torque FF are also considered as inputs. Since the ML model needs a target value to learn and the encoder and current values being not accurate and FTS sensor was attached to the tcp and the model was trained on its 6 outputs Fx,Fy,Fz,Tx,Ty,Tz. using eqn this tcp wrench can be projected to the joint space thereby providing accurate  external torque. Although FTS sensors do have known issues like temperature drift and .. as mentioned in . This study assumes the external joint torque derived from the FTS readings are accurate. \n",
    "\n",
    "Similar to the previous chapters this too focuses on one joint for the sake of simplicty and for a baseline comparison before modelling for the entire robot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee033595-8783-495f-9079-ad9c937affed",
   "metadata": {},
   "source": [
    "## 3.3.1 Data Collection\n",
    "The robot was mounted vertically with the base attached to a horizontal plane. Joint 3 was rotated at a constant speed form -150째 to 150째. inroder to vary the gravitational load , joint 2 was also varied. Load was also varied. For each load 20 different joint velocitied and joint 2 angles were chosen from a uniform ditribution ranging form -13째 to 13째 and valocits from []. \n",
    "\n",
    "Data collection included recording FTS readings, joint velocity, joint angle, torque feedforward, motor torque, load-side encoder counts, and motor-side encoder counts at every 2 ms interval. This high-resolution data sampling ensured that detailed and accurate information was captured. A sampling time of 2ms was maintined to meet ral time processing needs and to ensure good good data was captured since only joint 3 is used, it makes sense to only use the orthogonal companents from FTS data as targets like Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8fd9c-f856-45fc-bde5-bb494c53ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to download the data\n",
    "from utils.download_utils import download_and_extract_zip\n",
    "\n",
    "data = download_and_extract_zip(\"ML1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73dff8-5c8c-454b-b8be-d8b3b93c5d95",
   "metadata": {},
   "source": [
    "## 3.3.2 inputs Data Preprocessing\n",
    "The inputs used for Analytical methods and Motor current based approach are used here, like joint velocity, motor current, torque feedforward, motor side and load side encoder torques. These provide the necessary information for the model to estimate external joint torques. Joint angles, although an important compnent for gravity based torque was not included becuase this iformation is already present in the load side encoder measurements. In addition to this use giving enocder difference [refernce eqn] has also showed imprvement in the results.\n",
    "\n",
    "data preprocessing includes cleaning the data from nan values and normalizing [cite] each input to make the learning process easier for the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe430d5-b6a1-4c70-8d79-69e8286fc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A custom dataset class is created which handles loading raw csv files, preprocessing and sampling.\n",
    "from torch.utils.data import  Dataset\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_path, sequence_length=1,device=\"cpu\",mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            sequence_length: length of the input sequence\n",
    "            device : device to store the tensors\n",
    "            mode : train or test\n",
    "        \"\"\"\n",
    "        self.Xcolumns = [\"encoder_motorinc_3\" , \"encoder_loadinc_3\", \"joint_velocity_3\",\"joint_torque_current_3\",\"target_joint_torque_3\",\"joint_angles_3\"]\n",
    "        self.ycolumns = [\"fts_reading_1\",\"fts_reading_2\",\"fts_reading_3\",\"fts_reading_4\",\"fts_reading_5\",\"fts_reading_6\"]\n",
    "        self.data = pd.read_csv(csv_path, usecols = self.Xcolumns+self.ycolumns)\n",
    "        self.mode = mode\n",
    "        if self.mode == \"test\":\n",
    "            self.data = multiturn_compensation(self.data)\n",
    "        else:\n",
    "            pass\n",
    "        #self.data[\"encoder_difference_3\"] = 101*self.data[\"encoder_loadinc_3\"]-self.data[\"encoder_motorinc_3\"]\n",
    "        #self.Xcolumns.append(\"encoder_difference_3\")\n",
    "        self.data = self.data.dropna()\n",
    "        self.device = device\n",
    "        self.sequence_length = sequence_length\n",
    "        self.length = len(self.data) - self.sequence_length\n",
    "        self.X = torch.tensor(self.data[self.Xcolumns].values, device=self.device,dtype = torch.float32)\n",
    "        self.y = torch.tensor(self.data[self.ycolumns].values, device=self.device,dtype = torch.float32)\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            X_max = self.X.max(dim=0).values\n",
    "            X_min = self.X.min(dim=0).values\n",
    "            y_max = self.y.max(dim=0).values\n",
    "            y_min = self.y.min(dim=0).values\n",
    "            torch.save(X_max, \"utils/ML1/models/X_max.pt\")\n",
    "            torch.save(X_min, \"utils/ML1/models/X_min.pt\")\n",
    "            torch.save(y_max, \"utils/ML1/models/y_max.pt\")\n",
    "            torch.save(y_min, \"utils/ML1/models/y_min.pt\")\n",
    "        elif self.mode == \"test\":\n",
    "            X_max = torch.load(\"utils/ML1/models/X_max.pt\")\n",
    "            X_min = torch.load(\"utils/ML1/models/X_min.pt\")\n",
    "            y_max = torch.load(\"utils/ML1/models/y_max.pt\")\n",
    "            y_min = torch.load(\"utils/ML1/models/y_min.pt\")\n",
    "        else:\n",
    "            raise ValueError(\"mode should be either train or test\")\n",
    "        #normalize to -1 to 1 to be used with tanh activation function !! not for ReLU !!\n",
    "        self.X = 2*((self.X - X_min) / (X_max - X_min)) - 1\n",
    "        self.y = 2*((self.y - y_min) / (y_max - y_min)) - 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index:index+self.sequence_length]\n",
    "        y = self.y[index+self.sequence_length]\n",
    "        return (X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644e780-5239-47fb-87c3-d9a1ae98f654",
   "metadata": {},
   "source": [
    "## 3.3.3 Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd358d-6246-4605-9342-2ab00ac9acc0",
   "metadata": {},
   "source": [
    "For the model, there are 6 inputs and 6 outputs. the model should be large enought to learn he physical mapping from inputs to output without overfitting [cite] and be small enough to allow the deployment in the robot which has limited resources. This poses a particular challenge. starting from the simplest model of a fully connected network, then following with more complex architectures like RNN, GRU. One such model defenition is given in code cell [] below for refernce, other models are defined in model_defenitions.py[appendix] and imported. The weights were initialized with xavier normal [cite website and formula]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5773cf8-88ba-40ff-bfd9-ace5abf85516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ML1.model_defenitions import RNN, GRU, LSTM\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        self.fc4 = nn.Linear(256, output_size)\n",
    "        nn.init.xavier_normal_(self.fc4.weight)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.output_activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.activation(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.activation(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.output_activation(self.fc4(out))\n",
    "        return out\n",
    "visualize_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f3470-8c73-45e5-a52a-7e7b27b1c627",
   "metadata": {},
   "source": [
    "## 3.3.4 Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd397dc5-357b-4e4f-92c5-7440e90a8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "input_size = 7 # number of input features \n",
    "output_size = 6 # number of output (6 fts readings)\n",
    "\n",
    "dataset = CustomDatasetFromCSV(csv_path = '/mnt/data/ML1/data.csv',mode=\"train\")\n",
    "\n",
    "train_length = int(0.75* len(dataset))\n",
    "test_length = len(dataset)-train_length\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7cc6d-8413-4e76-8798-17a0f85b1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"utils/ML1/models/NN_model.pt\"\n",
    "if os.path.exists(file_path):\n",
    "    print(\"using pre-trained model\")\n",
    "    nn_model = torch.jit.load('utils/ML1/models/NN_model.pt', map_location=torch.device('cpu'))\n",
    "    rnn_model = torch.jit.load('utils/ML1/models/RNN_model.pt', map_location=torch.device('cpu'))\n",
    "    gru_model = torch.jit.load('utils/ML1/models/GRU_model.pt', map_location=torch.device('cpu'))\n",
    "    lstm_model = torch.jit.load('utils/ML1/models/LSTM_model.pt', map_location=torch.device('cpu'))\n",
    "else:\n",
    "    model = NN(input_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    # Train the model\n",
    "    n_total_steps = len(train_dataloader)\n",
    "    for epoch in range(EPOCHS):\n",
    "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for i, (X, y) in enumerate(progress_bar): \n",
    "            #Forward propagation\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            # Backpropagation and optimize\n",
    "            model.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41a2ac-902b-44ec-a5cb-cff394891631",
   "metadata": {},
   "source": [
    "## 3.3.3 Resuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a9c40-9556-4d50-b159-82900cf5a391",
   "metadata": {},
   "source": [
    "The results from the 4 differents models on the same validation trajectory which was not used for training is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb533995-528b-4016-9fbd-a5400e038ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to denormalize the predictions\n",
    "y_max = torch.load('utils/ML1/models/y_max.pt',map_location=torch.device('cpu'))\n",
    "y_min = torch.load('utils/ML1/models/y_min.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "dataset = CustomDatasetFromCSV(csv_path = 'utils/ML1/validate.csv', device = \"cpu\", mode=\"test\")\n",
    "test_dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():    \n",
    "    for i, (X,y) in enumerate(tqdm(test_dataloader)):\n",
    "        \n",
    "        pred = model(X)\n",
    "        pred = (pred+1)/2* (y_max - y_min) + y_min\n",
    "        pred_list.append(pred)\n",
    "\n",
    "#denormalize the data\n",
    "\n",
    "y_truth = ((test_dataloader.dataset.y + 1)/2* (y_max - y_min) + y_min).cpu().numpy()\n",
    "pred_list = torch.cat(pred_list).numpy()\n",
    "pred_list = pred_list.squeeze(1)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "# Plotting each component\n",
    "components = ['Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < y_truth.shape[1]:  # Ensure there are enough columns to plot\n",
    "        ax.plot(y_truth[:, i], label=\"truth\")\n",
    "        ax.plot(pred_list[:, i], label=\"prediction\")\n",
    "        ax.set_title(components[i])\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "# Add legend to the first subplot\n",
    "axes[0, 0].legend()\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a182d5-830d-4f45-a927-40ace1393f02",
   "metadata": {},
   "source": [
    "it is clear that GRU performs the best out of all. it is to be noted that hypermarameter optimization was not done for nay of these models and a set of recommended parameters were used for an initial comparison, although these results might vary when each model is further optimized , hwoever this will be done in the next chapter. But for a good first comparison this seems good. use of GRU or a recurrent neural network is also important as there are physical properties of the joint like hystersisi which rely on the previous state of the joint. hence moving forward the GRU architecture will be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054da4e-a1f9-4ec9-8b14-3fd32f0bf82b",
   "metadata": {},
   "source": [
    "## 3.3.4 Comparison with baseline approaches\n",
    "show how analytical methods fail when other joints are moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d1319-c9b0-4022-97b2-d9f7b87931c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv('utils/ML1/validate.csv')\n",
    "pred_df = pd.DataFrame(pred_list, columns = ['Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz'])\n",
    "#create empty arrays to store the results\n",
    "measured_external_force = np.zeros((len(input_df),6))\n",
    "calculated_external_force = np.zeros((len(input_df),6))\n",
    "estimated_external_force = np.zeros((len(input_df),6))\n",
    "\n",
    "for i, row in input_df.iterrows():\n",
    "\n",
    "    joint_angle = row[[\"joint_angles_1\",\"joint_angles_2\",\"joint_angles_3\",\"joint_angles_4\",\"joint_angles_5\",\"joint_angles_6\"]].values\n",
    "    joint_angle = np.array(joint_angle)\n",
    "    #print(joint_angle)\n",
    "    jacobian = compute_geometric_jacobian(joint_angle)\n",
    "    \n",
    "\n",
    "    joint_torque = row[[\"joint_torque_current_1\",\"joint_torque_current_2\",\"joint_torque_current_3\",\"joint_torque_current_4\",\"joint_torque_current_5\",\"joint_torque_current_6\"]].values\n",
    "    joint_torque = np.array(joint_torque)\n",
    "\n",
    "    idyn_torque = row[[\"target_joint_torque_1\",\"target_joint_torque_2\",\"target_joint_torque_3\",\"target_joint_torque_4\",\"target_joint_torque_5\",\"target_joint_torque_6\"]].values\n",
    "    idyn_torque = np.array(idyn_torque)\n",
    "    \n",
    "    fts_reading = row[[\"fts_reading_1\",\"fts_reading_2\",\"fts_reading_3\",\"fts_reading_4\",\"fts_reading_5\",\"fts_reading_6\"]]\n",
    "    fts_reading = np.array(fts_reading)\n",
    "    \n",
    "    measured_external_force[i] = jacobian.T@fts_reading\n",
    "    calculated_external_force[i] = joint_torque - idyn_torque\n",
    "    try:\n",
    "        estimated_external_force[i] = jacobian.T@pred_df.iloc[i].values # the dropna in the dataset will cause the index to be different could cause shifts in plot\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "#plot the results\n",
    "\n",
    "plt.suptitle('Comparison of measured (FTS), calculated (Motor torque - IDYN) \\n and estimated (ML model)external forces and torques')\n",
    "\n",
    "plt.plot(measured_external_force[:,2],label=\"measured\")\n",
    "plt.plot(calculated_external_force[:,2],label=\"calculated\")\n",
    "plt.plot(estimated_external_force[:,2],label=\"estimated\")\n",
    "plt.legend()\n",
    "plt.xlabel('idx')\n",
    "plt.ylabel('Force(N)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a5f5d-b902-4a1e-91f0-24925a177e87",
   "metadata": {},
   "source": [
    "from this it is clear that a machine learning based approach is quite suitable to model external joint torques. This leads to the next chapter where a single model will be used to predict the fts based on inputs from all the 6 joints."
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
